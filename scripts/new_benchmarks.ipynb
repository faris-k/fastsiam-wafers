{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Please note this script is an adaptation of the official ImageNette benchmarking script.\n",
    "The original GitHub link is provided below.\n",
    "\n",
    "Right now, it is setup to only evaluate our FastSiamModel. You can uncomment the other models\n",
    "to allow for a comparison.\n",
    "\n",
    "Note that this benchmark also supports a multi-GPU setup. If you run it on\n",
    "a system with multiple GPUs make sure that you kill all the processes when\n",
    "killing the application. Due to the way we setup this benchmark the distributed\n",
    "processes might continue the benchmark if one of the nodes is killed.\n",
    "If you know how to fix this don't hesitate to create an issue or PR :)\n",
    "You can download the ImageNette dataset from here: https://github.com/fastai/imagenette\n",
    "\n",
    "Code has been tested on a V100 GPU with 16GBytes of video memory.\n",
    "\n",
    "Code to reproduce the benchmark results:\n",
    "\n",
    "Overall Results with Original Script (5.3.2022):\n",
    "\n",
    "\n",
    "| Model         | Batch Size | Epochs |  KNN Test Accuracy |       Time | Peak GPU Usage |\n",
    "|---------------|------------|--------|--------------------|------------|----------------|\n",
    "| BarlowTwins   |        256 |    200 |              0.587 |   86.2 Min |      4.0 GByte |\n",
    "| BYOL          |        256 |    200 |              0.619 |   88.6 Min |      4.3 GByte |\n",
    "| DCL (*)       |        256 |    200 |              0.762 |   53.3 Min |      4.3 GByte |\n",
    "| DCLW (*)      |        256 |    200 |              0.755 |   53.7 Min |      4.3 GByte |\n",
    "| DINO (Res18)  |        256 |    200 |              0.736 |   86.5 Min |      4.1 GByte |\n",
    "| MSN (ViT-S)   |        256 |    200 |              0.741 |   92.7 Min |     16.3 GByte |\n",
    "| Moco          |        256 |    200 |              0.727 |   87.3 Min |      4.3 GByte |\n",
    "| NNCLR         |        256 |    200 |              0.726 |   86.8 Min |      4.2 GByte |\n",
    "| SimCLR        |        256 |    200 |              0.771 |   82.2 Min |      3.9 GByte |\n",
    "| SimSiam       |        256 |    200 |              0.669 |   78.6 Min |      3.9 GByte |\n",
    "| SMoG          |        128 |    200 |              0.698 |  220.9 Min |     14.3 GByte |\n",
    "| SwaV          |        256 |    200 |              0.748 |   77.6 Min |      4.0 GByte |\n",
    "|---------------|------------|--------|--------------------|------------|----------------|\n",
    "| BarlowTwins   |        256 |    800 |              0.789 |  330.9 Min |      4.0 GByte |\n",
    "| BYOL          |        256 |    800 |              0.851 |  332.7 Min |      4.3 GByte |\n",
    "| DCL (*)       |        256 |    800 |              0.816 |  213.1 Min |      4.3 GByte |\n",
    "| DCLW (*)      |        256 |    800 |              0.827 |  213.1 Min |      4.3 GByte |\n",
    "| DINO (Res18)  |        256 |    800 |              0.881 |  613.9 Min |      6.7 GByte |\n",
    "| MSN (ViT-S)   |        256 |    800 |              0.834 |  376.1 Min |     16.3 GByte |\n",
    "| Moco          |        256 |    800 |              0.832 |  322.8 Min |      4.2 GByte |\n",
    "| NNCLR         |        256 |    800 |              0.848 |  341.4 Min |      4.2 GByte |\n",
    "| SimCLR        |        256 |    800 |              0.858 |  324.8 Min |      3.9 GByte |\n",
    "| SimSiam       |        256 |    800 |              0.852 |  316.0 Min |      3.9 GByte |\n",
    "| SwaV          |        256 |    800 |              0.899 |  554.7 Min |      6.6 GByte |\n",
    "\n",
    "Our FastSiam Results (12.16.2022):\n",
    "Note that this was done by a college student on consumer-grade hardware, a 3080 10GB ðŸ˜‰\n",
    "| Model         | Batch Size | Epochs |  KNN Test Accuracy |       Time | Peak GPU Usage |\n",
    "|---------------|------------|--------|--------------------|------------|----------------|\n",
    "| FastSiam      |         16 |    200 |              0.675 |  717.9 Min |      4.7 GByte |\n",
    "\n",
    "(*): Different runtime and memory requirements due to different hardware settings\n",
    "and pytorch version. Runtime and memory requirements are comparable to SimCLR\n",
    "with the default settings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import lightly\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from lightly.data.collate import MultiViewCollateFunction, SimCLRCollateFunction\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models import modules, utils\n",
    "from lightly.models.modules import heads, masked_autoencoder\n",
    "from lightly.utils import knn_predict, BenchmarkModule\n",
    "from lightly.utils.debug import std_of_l2_normalized\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassAUROC,\n",
    "    MulticlassF1Score,\n",
    "    Accuracy\n",
    ")\n",
    "from utils.benchmarking import KNNBenchmarkModule\n",
    "from torchmetrics.functional.classification import (\n",
    "    multiclass_accuracy,\n",
    "    multiclass_f1_score,\n",
    ")\n",
    "import warnings\n",
    "\n",
    "# suppress annoying torchmetrics and lightning warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*interpolation.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*meaningless.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*log_every_n_steps.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                     | Params\n",
      "-------------------------------------------------------------\n",
      "0 | backbone        | Sequential               | 11.2 M\n",
      "1 | val_accuracy    | MulticlassAccuracy       | 0     \n",
      "2 | val_f1          | MulticlassF1Score        | 0     \n",
      "3 | projection_head | SimSiamProjectionHead    | 9.4 M \n",
      "4 | prediction_head | SimSiamPredictionHead    | 2.1 M \n",
      "5 | criterion       | NegativeCosineSimilarity | 0     \n",
      "-------------------------------------------------------------\n",
      "22.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.7 M    Total params\n",
      "90.888    Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | backbone        | Sequential           | 11.2 M\n",
      "1 | val_accuracy    | MulticlassAccuracy   | 0     \n",
      "2 | val_f1          | MulticlassF1Score    | 0     \n",
      "3 | projection_head | SimCLRProjectionHead | 328 K \n",
      "4 | criterion       | NTXentLoss           | 0     \n",
      "---------------------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 M    Total params\n",
      "46.019    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'SimSiam', 'batch_size': 32, 'epochs': 2, 'max_accuracy': 0.2592370808124542, 'runtime': 151.24412941932678, 'gpu_memory_usage': 851222528, 'seed': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'SimCLR', 'batch_size': 32, 'epochs': 2, 'max_accuracy': 0.3470922112464905, 'runtime': 150.45636916160583, 'gpu_memory_usage': 690014208, 'seed': 0}\n",
      "------------------------------------------------------------------------------------------\n",
      "| Model         | Batch Size | Epochs |  KNN Test Accuracy |       Time | Peak GPU Usage |\n",
      "------------------------------------------------------------------------------------------\n",
      "| SimSiam       |         32 |      2 |              0.259 |    2.5 Min |      0.8 GByte |\n",
      "| SimCLR        |         32 |      2 |              0.347 |    2.5 Min |      0.6 GByte |\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "logs_root_dir = os.path.join(os.getcwd(), \"benchmark_logs\")\n",
    "\n",
    "num_workers = 12\n",
    "memory_bank_size = 4096\n",
    "\n",
    "# set max_epochs to 800 for long run (takes around 10h on a single V100)\n",
    "max_epochs = 2\n",
    "knn_k = 200\n",
    "knn_t = 0.1\n",
    "classes = 10\n",
    "input_size = 128\n",
    "\n",
    "# Â Set to True to enable Distributed Data Parallel training.\n",
    "distributed = False\n",
    "\n",
    "# Set to True to enable Synchronized Batch Norm (requires distributed=True).\n",
    "# If enabled the batch norm is calculated over all gpus, otherwise the batch\n",
    "# norm is only calculated from samples on the same gpu.\n",
    "sync_batchnorm = False\n",
    "\n",
    "# Set to True to gather features from all gpus before calculating\n",
    "# the loss (requires distributed=True).\n",
    "# Â If enabled then the loss on every gpu is calculated with features from all\n",
    "# gpus, otherwise only features from the same gpu are used.\n",
    "gather_distributed = False\n",
    "\n",
    "# benchmark\n",
    "n_runs = 1  # optional, increase to create multiple runs and report mean + std\n",
    "batch_size = 32\n",
    "lr_factor = batch_size / 256  # Â scales the learning rate linearly with batch size\n",
    "\n",
    "# use a GPU if available\n",
    "gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "\n",
    "if distributed:\n",
    "    distributed_backend = \"ddp\"\n",
    "    # reduce batch size for distributed training\n",
    "    batch_size = batch_size // gpus\n",
    "else:\n",
    "    distributed_backend = None\n",
    "    # limit to single gpu if not using distributed training\n",
    "    gpus = min(gpus, 1)\n",
    "\n",
    "# The dataset structure should be like this:\n",
    "\n",
    "path_to_train = \"../data/datasets/imagenette2-160/train\"\n",
    "path_to_test = \"../data/datasets/imagenette2-160/val\"\n",
    "\n",
    "# Use SimCLR augmentations\n",
    "collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=input_size,\n",
    ")\n",
    "\n",
    "# Multi crop augmentation for SwAV\n",
    "swav_collate_fn = lightly.data.SwaVCollateFunction(\n",
    "    crop_sizes=[128, 64],\n",
    "    crop_counts=[2, 6],  # 2 crops @ 128x128px and 6 crops @ 64x64px\n",
    ")\n",
    "\n",
    "# Multi crop augmentation for DINO, additionally, disable blur for cifar10\n",
    "dino_collate_fn = lightly.data.DINOCollateFunction(\n",
    "    global_crop_size=128,\n",
    "    local_crop_size=64,\n",
    ")\n",
    "\n",
    "# Two crops for SMoG\n",
    "smog_collate_function = lightly.data.collate.SMoGCollateFunction(\n",
    "    crop_sizes=[128, 128],\n",
    "    crop_counts=[1, 1],\n",
    "    crop_min_scales=[0.2, 0.2],\n",
    "    crop_max_scales=[1.0, 1.0],\n",
    ")\n",
    "\n",
    "# Â Single crop augmentation for MAE\n",
    "mae_collate_fn = lightly.data.MAECollateFunction()\n",
    "\n",
    "# Multi crop augmentation for MSN\n",
    "msn_collate_fn = lightly.data.MSNCollateFunction(random_size=128, focal_size=64)\n",
    "\n",
    "# FastSiam collate\n",
    "base_transforms = collate_fn.transform\n",
    "fast_siam_collate_fn = MultiViewCollateFunction([base_transforms] * 4)\n",
    "\n",
    "normalize_transform = torchvision.transforms.Normalize(\n",
    "    mean=lightly.data.collate.imagenet_normalize[\"mean\"],\n",
    "    std=lightly.data.collate.imagenet_normalize[\"std\"],\n",
    ")\n",
    "\n",
    "# No additional augmentations for the test set\n",
    "test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(input_size),\n",
    "        torchvision.transforms.CenterCrop(128),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        normalize_transform,\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_train_ssl = lightly.data.LightlyDataset(input_dir=path_to_train)\n",
    "\n",
    "# we use test transformations for getting the feature for kNN on train data\n",
    "dataset_train_kNN = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_train, transform=test_transforms\n",
    ")\n",
    "\n",
    "dataset_test = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_test, transform=test_transforms\n",
    ")\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size: int, model):\n",
    "    \"\"\"Helper method to create dataloaders for ssl, kNN train and kNN test\n",
    "\n",
    "    Args:\n",
    "        batch_size: Desired batch size for all dataloaders\n",
    "    \"\"\"\n",
    "    col_fn = collate_fn\n",
    "    if model == DINOModel:\n",
    "        col_fn = dino_collate_fn\n",
    "    elif model == MAEModel:\n",
    "        col_fn = mae_collate_fn\n",
    "    elif model == MSNModel:\n",
    "        col_fn = msn_collate_fn\n",
    "    elif model == FastSiamModel:\n",
    "        col_fn = fast_siam_collate_fn\n",
    "\n",
    "    dataloader_train_ssl = torch.utils.data.DataLoader(\n",
    "        dataset_train_ssl,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=col_fn,\n",
    "        drop_last=True,\n",
    "        # num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    dataloader_train_kNN = torch.utils.data.DataLoader(\n",
    "        dataset_train_kNN,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        # num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    dataloader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        # num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return dataloader_train_ssl, dataloader_train_kNN, dataloader_test\n",
    "\n",
    "\n",
    "class MocoModel(BenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        num_splits = 0 if sync_batchnorm else 8\n",
    "        # TODO: Add split batch norm to the resnet model\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        feature_dim = list(resnet.children())[-1].in_features\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "        # create a moco model based on ResNet\n",
    "        self.projection_head = heads.MoCoProjectionHead(feature_dim, 2048, 128)\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
    "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "        # create our loss with the optional memory bank\n",
    "        self.criterion = lightly.loss.NTXentLoss(\n",
    "            temperature=0.1, memory_bank_size=memory_bank_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(start_dim=1)\n",
    "        return self.projection_head(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "\n",
    "        # update momentum\n",
    "        utils.update_momentum(self.backbone, self.backbone_momentum, 0.99)\n",
    "        utils.update_momentum(self.projection_head, self.projection_head_momentum, 0.99)\n",
    "\n",
    "        def step(x0_, x1_):\n",
    "            x1_, shuffle = utils.batch_shuffle(x1_, distributed=distributed)\n",
    "            x0_ = self.backbone(x0_).flatten(start_dim=1)\n",
    "            x0_ = self.projection_head(x0_)\n",
    "\n",
    "            x1_ = self.backbone_momentum(x1_).flatten(start_dim=1)\n",
    "            x1_ = self.projection_head_momentum(x1_)\n",
    "            x1_ = utils.batch_unshuffle(x1_, shuffle, distributed=distributed)\n",
    "            return x0_, x1_\n",
    "\n",
    "        # We use a symmetric loss (model trains faster at little compute overhead)\n",
    "        # https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb\n",
    "        loss_1 = self.criterion(*step(x0, x1))\n",
    "        loss_2 = self.criterion(*step(x1, x0))\n",
    "\n",
    "        loss = 0.5 * (loss_1 + loss_2)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = list(self.backbone.parameters()) + list(\n",
    "            self.projection_head.parameters()\n",
    "        )\n",
    "        optim = torch.optim.SGD(\n",
    "            params,\n",
    "            lr=6e-2 * lr_factor,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "\n",
    "class SimCLRModel(KNNBenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        feature_dim = list(resnet.children())[-1].in_features\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.projection_head = heads.SimCLRProjectionHead(feature_dim, feature_dim, 128)\n",
    "        self.criterion = lightly.loss.NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(x)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(), lr=6e-2 * lr_factor, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "\n",
    "class SimSiamModel(KNNBenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        feature_dim = list(resnet.children())[-1].in_features\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.projection_head = heads.SimSiamProjectionHead(feature_dim, 2048, 2048)\n",
    "        self.prediction_head = heads.SimSiamPredictionHead(2048, 512, 2048)\n",
    "        self.criterion = lightly.loss.NegativeCosineSimilarity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(f)\n",
    "        p = self.prediction_head(z)\n",
    "        z = z.detach()\n",
    "        return z, p\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0, p0 = self.forward(x0)\n",
    "        z1, p1 = self.forward(x1)\n",
    "        loss = 0.5 * (self.criterion(z0, p1) + self.criterion(z1, p0))\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=6e-2,  # Â no lr-scaling, results in better training stability\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "\n",
    "class BarlowTwinsModel(BenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        feature_dim = list(resnet.children())[-1].in_features\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        # use a 2-layer projection head for cifar10 as described in the paper\n",
    "        self.projection_head = heads.BarlowTwinsProjectionHead(feature_dim, 2048, 2048)\n",
    "\n",
    "        self.criterion = lightly.loss.BarlowTwinsLoss(\n",
    "            gather_distributed=gather_distributed\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(x)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(), lr=6e-2 * lr_factor, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "\n",
    "class BYOLModel(BenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        feature_dim = list(resnet.children())[-1].in_features\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "        # create a byol model based on ResNet\n",
    "        self.projection_head = heads.BYOLProjectionHead(feature_dim, 4096, 256)\n",
    "        self.prediction_head = heads.BYOLPredictionHead(256, 4096, 256)\n",
    "\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
    "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "        self.criterion = lightly.loss.NegativeCosineSimilarity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(y)\n",
    "        p = self.prediction_head(z)\n",
    "        return p\n",
    "\n",
    "    def forward_momentum(self, x):\n",
    "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "        z = self.projection_head_momentum(y)\n",
    "        z = z.detach()\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        utils.update_momentum(self.backbone, self.backbone_momentum, m=0.99)\n",
    "        utils.update_momentum(\n",
    "            self.projection_head, self.projection_head_momentum, m=0.99\n",
    "        )\n",
    "        (x0, x1), _, _ = batch\n",
    "        p0 = self.forward(x0)\n",
    "        z0 = self.forward_momentum(x0)\n",
    "        p1 = self.forward(x1)\n",
    "        z1 = self.forward_momentum(x1)\n",
    "        loss = 0.5 * (self.criterion(p0, z1) + self.criterion(p1, z0))\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = (\n",
    "            list(self.backbone.parameters())\n",
    "            + list(self.projection_head.parameters())\n",
    "            + list(self.prediction_head.parameters())\n",
    "        )\n",
    "        optim = torch.optim.SGD(\n",
    "            params,\n",
    "            lr=6e-2 * lr_factor,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "\n",
    "class DINOModel(BenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        feature_dim = list(resnet.children())[-1].in_features\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.head = heads.DINOProjectionHead(\n",
    "            feature_dim, 2048, 256, 2048, batch_norm=True\n",
    "        )\n",
    "        self.teacher_backbone = copy.deepcopy(self.backbone)\n",
    "        self.teacher_head = heads.DINOProjectionHead(\n",
    "            feature_dim, 2048, 256, 2048, batch_norm=True\n",
    "        )\n",
    "\n",
    "        utils.deactivate_requires_grad(self.teacher_backbone)\n",
    "        utils.deactivate_requires_grad(self.teacher_head)\n",
    "\n",
    "        self.criterion = lightly.loss.DINOLoss(output_dim=2048)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.head(y)\n",
    "        return z\n",
    "\n",
    "    def forward_teacher(self, x):\n",
    "        y = self.teacher_backbone(x).flatten(start_dim=1)\n",
    "        z = self.teacher_head(y)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        utils.update_momentum(self.backbone, self.teacher_backbone, m=0.99)\n",
    "        utils.update_momentum(self.head, self.teacher_head, m=0.99)\n",
    "        views, _, _ = batch\n",
    "        views = [view.to(self.device) for view in views]\n",
    "        global_views = views[:2]\n",
    "        teacher_out = [self.forward_teacher(view) for view in global_views]\n",
    "        student_out = [self.forward(view) for view in views]\n",
    "        loss = self.criterion(teacher_out, student_out, epoch=self.current_epoch)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        param = list(self.backbone.parameters()) + list(self.head.parameters())\n",
    "        optim = torch.optim.SGD(\n",
    "            param,\n",
    "            lr=6e-2 * lr_factor,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "\n",
    "class MAEModel(BenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "\n",
    "        decoder_dim = 512\n",
    "        vit = torchvision.models.vit_b_32(pretrained=False)\n",
    "\n",
    "        self.warmup_epochs = 40 if max_epochs >= 800 else 20\n",
    "        self.mask_ratio = 0.75\n",
    "        self.patch_size = vit.patch_size\n",
    "        self.sequence_length = vit.seq_length\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_dim))\n",
    "        self.backbone = masked_autoencoder.MAEBackbone.from_vit(vit)\n",
    "        self.decoder = masked_autoencoder.MAEDecoder(\n",
    "            seq_length=vit.seq_length,\n",
    "            num_layers=1,\n",
    "            num_heads=16,\n",
    "            embed_input_dim=vit.hidden_dim,\n",
    "            hidden_dim=decoder_dim,\n",
    "            mlp_dim=decoder_dim * 4,\n",
    "            out_dim=vit.patch_size**2 * 3,\n",
    "            dropout=0,\n",
    "            attention_dropout=0,\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward_encoder(self, images, idx_keep=None):\n",
    "        return self.backbone.encode(images, idx_keep)\n",
    "\n",
    "    def forward_decoder(self, x_encoded, idx_keep, idx_mask):\n",
    "        # build decoder input\n",
    "        batch_size = x_encoded.shape[0]\n",
    "        x_decode = self.decoder.embed(x_encoded)\n",
    "        x_masked = utils.repeat_token(\n",
    "            self.mask_token, (batch_size, self.sequence_length)\n",
    "        )\n",
    "        x_masked = utils.set_at_index(x_masked, idx_keep, x_decode)\n",
    "\n",
    "        # decoder forward pass\n",
    "        x_decoded = self.decoder.decode(x_masked)\n",
    "\n",
    "        # predict pixel values for masked tokens\n",
    "        x_pred = utils.get_at_index(x_decoded, idx_mask)\n",
    "        x_pred = self.decoder.predict(x_pred)\n",
    "        return x_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, _, _ = batch\n",
    "\n",
    "        batch_size = images.shape[0]\n",
    "        idx_keep, idx_mask = utils.random_token_mask(\n",
    "            size=(batch_size, self.sequence_length),\n",
    "            mask_ratio=self.mask_ratio,\n",
    "            device=images.device,\n",
    "        )\n",
    "        x_encoded = self.forward_encoder(images, idx_keep)\n",
    "        x_pred = self.forward_decoder(x_encoded, idx_keep, idx_mask)\n",
    "\n",
    "        # get image patches for masked tokens\n",
    "        patches = utils.patchify(images, self.patch_size)\n",
    "        # must adjust idx_mask for missing class token\n",
    "        target = utils.get_at_index(patches, idx_mask - 1)\n",
    "\n",
    "        loss = self.criterion(x_pred, target)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=1.5e-4 * lr_factor,\n",
    "            weight_decay=0.05,\n",
    "            betas=(0.9, 0.95),\n",
    "        )\n",
    "        cosine_with_warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            optim, self.scale_lr\n",
    "        )\n",
    "        return [optim], [cosine_with_warmup_scheduler]\n",
    "\n",
    "    def scale_lr(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            return epoch / self.warmup_epochs\n",
    "        else:\n",
    "            return 0.5 * (\n",
    "                1.0\n",
    "                + math.cos(\n",
    "                    math.pi\n",
    "                    * (epoch - self.warmup_epochs)\n",
    "                    / (max_epochs - self.warmup_epochs)\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "class MSNModel(BenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "\n",
    "        self.warmup_epochs = 15\n",
    "        # Â ViT small configuration (ViT-S/16) = dict(patch_size=16, embed_dim=384, depth=12, num_heads=6)\n",
    "        #  ViT tiny configuration (ViT-T/16) = dict(patch_size=16, embed_dim=192, depth=12, num_heads=3)\n",
    "        self.mask_ratio = 0.15\n",
    "        self.backbone = masked_autoencoder.MAEBackbone(\n",
    "            image_size=224,\n",
    "            patch_size=16,\n",
    "            num_layers=12,\n",
    "            num_heads=6,\n",
    "            hidden_dim=384,\n",
    "            mlp_dim=384 * 4,\n",
    "        )\n",
    "        self.projection_head = heads.MSNProjectionHead(384)\n",
    "\n",
    "        self.anchor_backbone = copy.deepcopy(self.backbone)\n",
    "        self.anchor_projection_head = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        utils.deactivate_requires_grad(self.backbone)\n",
    "        utils.deactivate_requires_grad(self.projection_head)\n",
    "\n",
    "        self.prototypes = nn.Linear(256, 1024, bias=False).weight\n",
    "        self.criterion = lightly.loss.MSNLoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        utils.update_momentum(self.anchor_backbone, self.backbone, 0.996)\n",
    "        utils.update_momentum(self.anchor_projection_head, self.projection_head, 0.996)\n",
    "\n",
    "        views, _, _ = batch\n",
    "        views = [view.to(self.device, non_blocking=True) for view in views]\n",
    "        targets = views[0]\n",
    "        anchors = views[1]\n",
    "        anchors_focal = torch.concat(views[2:], dim=0)\n",
    "\n",
    "        targets_out = self.backbone(targets)\n",
    "        targets_out = self.projection_head(targets_out)\n",
    "        anchors_out = self.encode_masked(anchors)\n",
    "        anchors_focal_out = self.encode_masked(anchors_focal)\n",
    "        anchors_out = torch.cat([anchors_out, anchors_focal_out], dim=0)\n",
    "\n",
    "        loss = self.criterion(anchors_out, targets_out, self.prototypes.data)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def encode_masked(self, anchors):\n",
    "        batch_size, _, _, width = anchors.shape\n",
    "        seq_length = (width // self.anchor_backbone.patch_size) ** 2\n",
    "        idx_keep, _ = utils.random_token_mask(\n",
    "            size=(batch_size, seq_length),\n",
    "            mask_ratio=self.mask_ratio,\n",
    "            device=self.device,\n",
    "        )\n",
    "        out = self.anchor_backbone(anchors, idx_keep)\n",
    "        return self.anchor_projection_head(out)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = [\n",
    "            *list(self.anchor_backbone.parameters()),\n",
    "            *list(self.anchor_projection_head.parameters()),\n",
    "            self.prototypes,\n",
    "        ]\n",
    "        optim = torch.optim.AdamW(\n",
    "            params=params,\n",
    "            lr=1.5e-4 * lr_factor,\n",
    "            weight_decay=0.05,\n",
    "            betas=(0.9, 0.95),\n",
    "        )\n",
    "        cosine_with_warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            optim, self.scale_lr\n",
    "        )\n",
    "        return [optim], [cosine_with_warmup_scheduler]\n",
    "\n",
    "    def scale_lr(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            return epoch / self.warmup_epochs\n",
    "        else:\n",
    "            return 0.5 * (\n",
    "                1.0\n",
    "                + math.cos(\n",
    "                    math.pi\n",
    "                    * (epoch - self.warmup_epochs)\n",
    "                    / (max_epochs - self.warmup_epochs)\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class FastSiamModel(KNNBenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN, num_classes):\n",
    "        super().__init__(dataloader_kNN, num_classes)\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        feature_dim = list(resnet.children())[-1].in_features\n",
    "        self.backbone = timm.create_model(\"resnet18\", num_classes=0)\n",
    "        self.projection_head = heads.SimSiamProjectionHead(feature_dim, 2048, 2048)\n",
    "        self.prediction_head = heads.SimSiamPredictionHead(2048, 512, 2048)\n",
    "        self.criterion = lightly.loss.NegativeCosineSimilarity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(f)\n",
    "        p = self.prediction_head(z)\n",
    "        z = z.detach()\n",
    "        return z, p\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0, p0 = self.forward(x0)\n",
    "        z1, p1 = self.forward(x1)\n",
    "        loss = 0.5 * (self.criterion(z0, p1) + self.criterion(z1, p0))\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Unpack augmented views\n",
    "        views, _, _ = batch\n",
    "        x1, x2, x3, x4 = views\n",
    "\n",
    "        # Pass each view through projector to get z, and predictor to get p\n",
    "        z1, p1 = self.forward(x1)\n",
    "        z2, p2 = self.forward(x2)\n",
    "        z3, p3 = self.forward(x3)\n",
    "        z4, p4 = self.forward(x4)\n",
    "\n",
    "        # Use mean of the last N - 1 projected views\n",
    "        mean = (z2 + z3 + z4) / 3\n",
    "\n",
    "        # Compute loss using prediction of 1st view, mean of remaining projected views\n",
    "        loss = self.criterion(p1, mean)\n",
    "\n",
    "        # Keep a log of the loss\n",
    "        self.log(\"loss\", loss)\n",
    "        # Monitor the STD of L2-normalized representation to check if it collapses (bad)\n",
    "        self.log(\"z1 std\", std_of_l2_normalized(z1))\n",
    "        # self.log(\"z2 std\", std_of_l2_normalized(z2))\n",
    "        # self.log(\"z3 std\", std_of_l2_normalized(z3))\n",
    "        # self.log(\"z4 std\", std_of_l2_normalized(z4))\n",
    "\n",
    "        # self.log(\"mean std\", std_of_l2_normalized(mean))\n",
    "\n",
    "        # self.log(\"p1 std\", std_of_l2_normalized(p1))\n",
    "        # self.log(\"p2 std\", std_of_l2_normalized(p2))\n",
    "        # self.log(\"p3 std\", std_of_l2_normalized(p3))\n",
    "        # self.log(\"p4 std\", std_of_l2_normalized(p4))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.parameters(), lr=0.06)\n",
    "        return optim\n",
    "\n",
    "\n",
    "models = [\n",
    "    # FastSiamModel,\n",
    "    SimSiamModel,\n",
    "    SimCLRModel,\n",
    "    # MocoModel,\n",
    "    # DINOModel\n",
    "    # BarlowTwinsModel,\n",
    "    # BYOLModel,\n",
    "    # DCL,\n",
    "    # DCLW,\n",
    "    # DINOModel,\n",
    "    # #Â MAEModel, #Â disabled by default because MAE uses larger images with size 224\n",
    "    # #Â MSNModel, #Â disabled by default because MSN uses larger images with size 224\n",
    "    # MocoModel,\n",
    "    # NNCLRModel,\n",
    "    # SimCLRModel,\n",
    "    # SimSiamModel,\n",
    "    # SwaVModel,\n",
    "    # SMoGModel\n",
    "]\n",
    "bench_results = dict()\n",
    "\n",
    "experiment_version = None\n",
    "# loop through configurations and train models\n",
    "for BenchmarkModel in models:\n",
    "    runs = []\n",
    "    model_name = BenchmarkModel.__name__.replace(\"Model\", \"\")\n",
    "    for seed in range(n_runs):\n",
    "        pl.seed_everything(seed)\n",
    "        dataloader_train_ssl, dataloader_train_kNN, dataloader_test = get_data_loaders(\n",
    "            batch_size=batch_size,\n",
    "            model=BenchmarkModel,\n",
    "        )\n",
    "        benchmark_model = BenchmarkModel(dataloader_train_kNN, classes)\n",
    "\n",
    "        # Save logs to: {CWD}/benchmark_logs/cifar10/{experiment_version}/{model_name}/\n",
    "        # If multiple runs are specified a subdirectory for each run is created.\n",
    "        sub_dir = model_name if n_runs <= 1 else f\"{model_name}/run{seed}\"\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=os.path.join(logs_root_dir, \"imagenette\"),\n",
    "            name=\"\",\n",
    "            sub_dir=sub_dir,\n",
    "            version=experiment_version,\n",
    "        )\n",
    "        if experiment_version is None:\n",
    "            # Save results of all models under same version directory\n",
    "            experiment_version = logger.version\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            dirpath=os.path.join(logger.log_dir, \"checkpoints\")\n",
    "        )\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=max_epochs,\n",
    "            accelerator=\"gpu\",\n",
    "            default_root_dir=logs_root_dir,\n",
    "            strategy=distributed_backend,\n",
    "            sync_batchnorm=sync_batchnorm,\n",
    "            logger=logger,\n",
    "            callbacks=[checkpoint_callback],\n",
    "            enable_progress_bar=False,\n",
    "        )\n",
    "        start = time.time()\n",
    "        trainer.fit(\n",
    "            benchmark_model,\n",
    "            train_dataloaders=dataloader_train_ssl,\n",
    "            val_dataloaders=dataloader_test,\n",
    "        )\n",
    "        end = time.time()\n",
    "        run = {\n",
    "            \"model\": model_name,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": max_epochs,\n",
    "            \"max_accuracy\": benchmark_model.max_accuracy,\n",
    "            \"runtime\": end - start,\n",
    "            \"gpu_memory_usage\": torch.cuda.max_memory_allocated(),\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "        runs.append(run)\n",
    "        print(run)\n",
    "\n",
    "        # delete model and trainer + free up cuda memory\n",
    "        del benchmark_model\n",
    "        del trainer\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    bench_results[model_name] = runs\n",
    "\n",
    "# Â print results table\n",
    "header = (\n",
    "    f\"| {'Model':<13} | {'Batch Size':>10} | {'Epochs':>6} \"\n",
    "    f\"| {'KNN Test Accuracy':>18} | {'Time':>10} | {'Peak GPU Usage':>14} |\"\n",
    ")\n",
    "print(\"-\" * len(header))\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for model, results in bench_results.items():\n",
    "    runtime = np.array([result[\"runtime\"] for result in results])\n",
    "    runtime = runtime.mean() / 60  # convert to min\n",
    "    accuracy = np.array([result[\"max_accuracy\"] for result in results])\n",
    "    gpu_memory_usage = np.array([result[\"gpu_memory_usage\"] for result in results])\n",
    "    gpu_memory_usage = gpu_memory_usage.max() / (1024**3)  # Â convert to gbyte\n",
    "\n",
    "    if len(accuracy) > 1:\n",
    "        accuracy_msg = f\"{accuracy.mean():>8.3f} +- {accuracy.std():>4.3f}\"\n",
    "    else:\n",
    "        accuracy_msg = f\"{accuracy.mean():>18.3f}\"\n",
    "\n",
    "    print(\n",
    "        f\"| {model:<13} | {batch_size:>10} | {max_epochs:>6} \"\n",
    "        f\"| {accuracy_msg} | {runtime:>6.1f} Min \"\n",
    "        f\"| {gpu_memory_usage:>8.1f} GByte |\",\n",
    "        flush=True,\n",
    "    )\n",
    "print(\"-\" * len(header))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51c7e371e7f0e705fbface39e2a6c77c02ee1bbdcc1060cdfeb54e5726145823"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
